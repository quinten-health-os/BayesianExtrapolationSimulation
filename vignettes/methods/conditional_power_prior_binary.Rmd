---
title: "Conditional power prior with binary data"
author: "Tristan Fauvel, Quinten Health"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: cerulean
    toc: yes
    toc_float:
      collapsed: true
resource_files:
  - images/RMP_binary.png
vignette: >
  %\VignetteIndexEntry{Introduction to MyPackage}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\VignetteDepends{RBExT, ggplot2}
---

## Introduction

This vignette describes an implementation of the Conditional Power Prior when the treatment effect is the difference between the success rate in the treatment arm and the success rate in the control arm. 

## Set working directory, import functions and configurations

List packages to load, and install them if necessary.
```{r setup, warning=FALSE, include = FALSE} 
root <- dirname(dirname(getwd()))
knitr::opts_knit$set(root.dir = root, warning = FALSE, message = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

library(RBExT)
library(ggplot2)
library(cmdstanr)
```

## Load the data for the Aprepitant case study

```{r} 
set.seed(42)
config_path <- system.file("conf/full/simulation_config.yml", package = "RBExT")
simulation_config <- yaml::yaml.load_file(config_path)

case_study <- "aprepitant"
config_path <- system.file("conf/case_studies/aprepitant.yml", package = "RBExT")
case_study_config <- yaml::yaml.load_file(config_path)

source_data <- ObservedSourceData$new(case_study_config)

target_data <- ObservedTargetData$new(treatment_effect_estimate = case_study_config$target$treatment_effect, treatment_effect_standard_error = case_study_config$target$standard_error, target_sample_size_per_arm = as.integer(case_study_config$target$total / 2), summary_measure_likelihood = case_study_config$summary_measure_likelihood)
``` 

## Model for the rate difference

In the figure below, we represent the model used in the case where the treatment effect is a difference of rates. On the figures, we represent the case where we put a robust mixture prior on the treatment effect, in our case, however we will put a Conditional Power Prior on it: 

![alt text](./vignettes/images/RMP_binary.png)
The model can be summarized as follows:

* $y_T^{c} \sim \mathcal{B}(p_T^{c},N_T^{c})$
* $y_T^{t} \sim \mathcal{B}(p_T^{t},N_T^{t})$
* $p_T^{c} \sim \mathcal{U}(0,1)$
* $p_T^{t} = \theta_T - p_T^{c}$
and we put a Conditional Power Prior informed by source study data on the treatment effect: 
$p(\theta_T |\mathbf{D}_S, \gamma) \propto \mathcal{L}(\theta_T|\mathbf{D}_S)^\gamma\pi_0(\theta_T)$
 

## Implementation of the model in Stan

Let us define the Stan model:

```{r}
stan_model_code <- "
data {
  int<lower = 0> n_treatment_source; // number of patients in the treatment group of the source study
  int<lower = 0> n_control_source; // number of patients in the control group of the source study

  int<lower = 0, upper = n_treatment_source> successes_treatment_source;  // number of successes in the treatment group of the source study
  int<lower = 0, upper = n_control_source> successes_control_source; // number of successes in the control group of the source study

  int<lower = 0> n_treatment_target; // number of patients in the treatment group of the target study
  int<lower = 0> n_control_target; // number of patients in the control group of the target study

  int<lower = 0, upper = n_treatment_target> successes_treatment_target;  // number of successes in the treatment group of the target study
  int<lower = 0, upper = n_control_target> successes_control_target; // number of successes in the control group of the target study

  int<lower = 0, upper = 1> gamma; // power parameter
}
parameters {
  real<lower = 0, upper = 1> control_rate_source;
  real<lower = 0, upper = 1> control_rate_target;
  real<lower = -1, upper = 1> treatment_effect; // The power prior approach assumes that the treatment effect is the same in the source and target studies
}
transformed parameters {
  real treatment_rate_source = control_rate_source + treatment_effect;
  real treatment_rate_target = control_rate_target + treatment_effect;
}
model {
  control_rate_target ~ uniform(0, 1);
  control_rate_source ~ uniform(0, 1);

  treatment_effect ~ uniform(-1, 1); // Initial prior on the treatment effect

  target += gamma * (binomial_lpmf(successes_control_source |n_control_source, control_rate_source) +
  binomial_lpmf(successes_treatment_source |n_treatment_source, treatment_rate_source)); // Likelihood of the source study p(D_S|treatment_effect)
  // Note that here, we implicitly borrow from the two arms

  successes_control_target ~ binomial(n_control_target, control_rate_target);
  successes_treatment_target ~ binomial(n_treatment_target, treatment_rate_target);
}
"
# Write the Stan code to a temporary file
stan_file_path <- cmdstanr::write_stan_file(stan_model_code)

# Compile the model
mod <- cmdstanr::cmdstan_model(stan_file_path)
```

## Fit the model with $\gamma  = 0.5$ 

```{r, results='hide'}
# Specify the parameters
data_list <- list(
  gamma = 0.5,
  n_treatment_source = case_study_config$source$treatment,
  n_control_source = case_study_config$source$control,
  successes_treatment_source = case_study_config$source$responses$treatment,
  successes_control_source = case_study_config$source$responses$control,
  n_treatment_target = case_study_config$target$treatment,
  n_control_target = case_study_config$target$control,
  successes_treatment_target = case_study_config$target$responses$treatment,
  successes_control_target = case_study_config$target$responses$control
)

# Sample from the posterior
fit <- mod$sample(
  data = data_list,
  chains = 4,
  parallel_chains = 4,
  iter_sampling = 2000,
  iter_warmup = 1000
)
```

```{r}
bayesplot::mcmc_hist(fit$draws("treatment_effect"), binwidth = 0.001) + xlim(-1, 1)
```


```{r}
library(posterior)
draws_array <- as_draws_array(fit)
```

```{r}
library(bayesplot)
mcmc_trace(draws_array, pars = c("control_rate_target", "treatment_rate_source", "treatment_effect"))
```

```{r}
mcmc_acf(draws_array, pars = c("control_rate_target", "treatment_rate_source", "treatment_effect"))
```

 
## Fit the model with $\gamma  = 0$ (no borrowing) 

```{r, results='hide'}
# Specify the parameters
data_list <- list(
  gamma = 0,
  n_treatment_source = case_study_config$source$treatment,
  n_control_source = case_study_config$source$control,
  successes_treatment_source = case_study_config$source$responses$treatment,
  successes_control_source = case_study_config$source$responses$control,
  n_treatment_target = case_study_config$target$treatment,
  n_control_target = case_study_config$target$control,
  successes_treatment_target = case_study_config$target$responses$treatment,
  successes_control_target = case_study_config$target$responses$control
)

# Sample from the posterior
fit <- mod$sample(
  data = data_list,
  chains = 4,
  parallel_chains = 4,
  iter_sampling = 2000,
  iter_warmup = 1000
)
```

```{r}
bayesplot::mcmc_hist(fit$draws("treatment_effect"), binwidth = 0.001) + xlim(-1, 1)
```

## Fit the model with $\gamma  = 1$ (pooling) 

```{r, results='hide'}
# Specify the parameters
data_list <- list(
  gamma = 1,
  n_treatment_source = case_study_config$source$treatment,
  n_control_source = case_study_config$source$control,
  successes_treatment_source = case_study_config$source$responses$treatment,
  successes_control_source = case_study_config$source$responses$control,
  n_treatment_target = case_study_config$target$treatment,
  n_control_target = case_study_config$target$control,
  successes_treatment_target = case_study_config$target$responses$treatment,
  successes_control_target = case_study_config$target$responses$control
)

# Sample from the posterior
fit <- mod$sample(
  data = data_list,
  chains = 4,
  parallel_chains = 4,
  iter_sampling = 2000,
  iter_warmup = 1000
)
```

```{r}
bayesplot::mcmc_hist(fit$draws("treatment_effect"), binwidth = 0.001) + xlim(-1, 1)
```

  
### Simulation 

Separate analysis:


```{r}
separate_method <- "separate"
method_parameters <- list(
  initial_prior = "noninformative", # This corresponds to the fact that the posterior for the adults data is derived from an uninformative prior (for consistency with other methods).
  empirical_bayes = FALSE # Corresponds to whether some parameters of the prior are based on observed data.
)

separate_model <- Model$new()

separate_model <- separate_model$create(
  case_study_config = case_study_config,
  method = separate_method,
  method_parameters = method_parameters,
  source_data = source_data,
  mcmc_config = mcmc_config
)
```

```{r}
treatment_effect_values <- seq(-7, 2, length.out = 200)

n <- length(treatment_effect_values)
confidence_level <- simulation_config$confidence_level
null_space <- case_study_config$null_space

n_replicates <- 100

separate_test_decisions <- matrix(rep(0, n * n_replicates), nrow = n)
separate_posterior_means <- matrix(rep(0, n * n_replicates), nrow = n)
separate_posterior_medians <- matrix(rep(0, n * n_replicates), nrow = n)
separate_credible_intervals <- array(rep(0, n * n_replicates * 2), dim = c(n, n_replicates, 2))
separate_prior_proba_no_benefit <- rep(0, n)

theta_0 <- case_study_config$theta_0

critical_value <- simulation_config$critical_value


for (i in seq_along(treatment_effect_values)) {
  drift <- treatment_effect_values[i] - source_data$treatment_effect_estimate
  target_data <- TargetDataFactory$new()

  target_data <- target_data$create(source_data = source_data, case_study_config = case_study_config, target_sample_size_per_arm = target_sample_size_per_arm, treatment_drift = drift, summary_measure_likelihood = source_data$summary_measure_likelihood)

  results <- separate_model$simulation_for_given_treatment_effect(target_data = target_data, n_replicates = n_replicates, critical_value = critical_value, theta_0 = theta_0, confidence_level = confidence_level, null_space = null_space, to_return = c("test_decision"), method = method, case_study = case_study)

  separate_test_decisions[i, ] <- results$test_decisions
  separate_posterior_means[i, ] <- results$posterior_means
  separate_posterior_medians[i, ] <- results$posterior_medians
  separate_credible_intervals[i, , ] <- matrix(results$credible_intervals, nrow = n_replicates)
}
```


```{r} 
test_decisions <- matrix(rep(0, n * n_replicates), nrow = n)
posterior_means <- matrix(rep(0, n * n_replicates), nrow = n)
posterior_medians <- matrix(rep(0, n * n_replicates), nrow = n)
credible_intervals <- array(rep(0, n * n_replicates * 2), dim = c(n, n_replicates, 2))
prior_proba_no_benefit <- rep(0, n)

for (i in seq_along(treatment_effect_values)) {
  drift <- treatment_effect_values[i] - source_data$treatment_effect_estimate # This implies that target_data$treatment_effect <- treatment_effect_values[i]
  target_data <- TargetDataFactory$new()

  target_data <- target_data$create(source_data = source_data, case_study_config = case_study_config, target_sample_size_per_arm = target_sample_size_per_arm, treatment_drift = drift, summary_measure_likelihood = source_data$summary_measure_likelihood)

  # target_data$sampling_approximation <- TRUE
  results <- model$simulation_for_given_treatment_effect(target_data = target_data, n_replicates = n_replicates, critical_value = critical_value, theta_0 = theta_0, confidence_level = confidence_level, null_space = null_space, to_return = c("test_decision"),  method = method, case_study = case_study)

  test_decisions[i, ] <- results$test_decisions
  posterior_means[i, ] <- results$posterior_means
  posterior_medians[i, ] <- results$posterior_medians
  credible_intervals[i, , ] <- matrix(results$credible_intervals, nrow = n_replicates)
}
```
 
```{r}
conditional_proba_success <- rowMeans(test_decisions) # Contains Pr(Study success | theta_T)
data <- data.frame(conditional_proba_success = conditional_proba_success, treatment_effect_values = treatment_effect_values, method = method)

separate_conditional_proba_success <- rowMeans(separate_test_decisions) # Contains Pr(Study success | theta_T)

separate_data <- data.frame(conditional_proba_success = separate_conditional_proba_success, treatment_effect_values = treatment_effect_values, method = separate_method)

combined_data <- rbind(data, separate_data)

plt <- ggplot(combined_data, aes(x = treatment_effect_values, y = conditional_proba_success, color = method)) +
  geom_point() +
  ggplot2::labs(
    title = "Posterior mean vs Target Treatment Effect",
    x = "Target Treatment Effect",
    y = "Success probability",
    color = "Method"
  ) +
  theme_minimal()

print(plt)
```
```{r}
separate_conditional_posterior_means <- rowMeans(separate_posterior_means)
separate_data <- data.frame(conditional_posterior_means = separate_conditional_posterior_means, treatment_effect_values = treatment_effect_values, method = separate_method)

conditional_posterior_means <- rowMeans(posterior_means)
data <- data.frame(conditional_posterior_means = conditional_posterior_means, treatment_effect_values = treatment_effect_values, method = method)

combined_data <- rbind(data, separate_data)

plt <- ggplot(combined_data, aes(x = treatment_effect_values, y = conditional_posterior_means, color = method)) +
  geom_point() +
  ggplot2::labs(
    title = "Posterior mean vs Target Treatment Effect",
    x = "Target Treatment Effect",
    y = "Posterior mean",
    color = "Method"
  ) +
  theme_minimal()

print(plt)
```
```{r}
sessionInfo()
```
 
