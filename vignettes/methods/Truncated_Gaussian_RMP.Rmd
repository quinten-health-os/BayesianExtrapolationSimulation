---
title: "Simulation study : RMP for binary endpoints without normal approximation for the treatment effect distribution"
author: "Tristan Fauvel, Quinten Health & Daniel Lee"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: cerulean
    toc: yes
    toc_float:
      collapsed: true
resource_files:
  - images/RMP_binary.png
vignette: >
  %\VignetteIndexEntry{Introduction to MyPackage}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\VignetteDepends{RBExT, ggplot2}
---

## Introduction

This vignette describes an implementation of the Truncated Gaussian Robust Mixture Prior when the treatment effect is the difference between the success rate in the treatment arm and the success rate in the control arm. 

## Set working directory, import functions and configurations

List packages to load, and install them if necessary.
```{r setup, warning=TRUE, include = FALSE} 
root <- dirname(dirname(getwd()))
knitr::opts_knit$set(root.dir = root, warning = FALSE, message = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

library(RBExT)
library(ggplot2)
library(cmdstanr)
```

## Load the data for the Aprepitant case study

```{r} 
set.seed(42)
config_path <- system.file("conf/full/simulation_config.yml", package = "RBExT")
simulation_config <- yaml::yaml.load_file(config_path)

case_study <- "aprepitant"
config_path <- system.file("conf/case_studies/aprepitant.yml", package = "RBExT")
case_study_config <- yaml::yaml.load_file(config_path)

source_data <- ObservedSourceData$new(case_study_config)


treatment_effect_standard_error <- case_study_config$target$standard_error

target_data <- ObservedTargetData$new(treatment_effect_estimate = case_study_config$target$treatment_effect, treatment_effect_standard_error = treatment_effect_standard_error, target_sample_size_per_arm = as.integer(case_study_config$target$total / 2), summary_measure_likelihood = case_study_config$summary_measure_likelihood)
``` 

## RMP for the rate difference

In the figure below, we represent the model used in the case where the treatment effect is a difference of rates, with a robust mixture prior on the treatment effect : 

![alt text](./vignettes/images/RMP_binary.png)
The model can be summarized as follows:

* $y_T^{c} \sim \mathcal{B}(p_T^{c},N_T^{c})$
* $y_T^{t} \sim \mathcal{B}(p_T^{t},N_T^{t})$
* $p_T^{c} \sim \mathcal{U}(0,1)$
* $p_T^{t} = \theta_T - p_T^{c}$
and we put a Truncated Gaussian Robust Mixture Prior on the treatment effect. This is the same logic as the standard Gaussian RMP, but the components are truncated between -1 and 1. That is : 
$$
p(\theta_T |\boldsymbol{y}_S)= w\mathcal{N}(\theta_T |\mu_v, \sigma^2_v, \text{lower} = -1, \text{upper} = 1) + (1-w)\mathcal{N}(\theta_T | \overline{y}_S, \nu^2_S, \text{lower} = -1, \text{upper} = 1)
$$
where 
$\mathcal{N}(\mu, \sigma^2, \text{lower} = -1, \text{upper} = 1)$ is the truncated normal distribution between -1 and 1, with p.d.f.:
$$f(x)=\frac{1}{\sigma} \frac{\varphi\left(\frac{x-\mu}{\sigma}\right)}{\Phi\left(\frac{1-\mu}{\sigma}\right)-\Phi\left(\frac{-1-\mu}{\sigma}\right)}$$

 

## Implementation of the model in Stan

Let us define the Stan model:

```{r}
stan_model_code <- "
data {
  int<lower = 0> n_treatment;
  int<lower = 0> n_control;

  int<lower = 0, upper = n_treatment> successes_treatment;
  int<lower = 0, upper = n_control> successes_control;

  real<lower = 0, upper = 1> w;

  real vague_mean;
  real<lower = 0> vague_sd;
  real info_mean;
  real<lower = 0> info_sd;
}
transformed data {
  int<lower = 0, upper = 1> debug = 0;
}
parameters {
  real<lower = 0, upper = 1> control_rate;
  real<lower = - control_rate, upper = 1 - control_rate> treatment_effect;
}
transformed parameters {
  real<lower = 0, upper = 1> treatment_rate = control_rate + treatment_effect;

  real vague_normalizing_constant = normal_cdf(1-control_rate | vague_mean, vague_sd) - normal_cdf(-control_rate | vague_mean, vague_sd);
  real info_normalizing_constant = normal_cdf(1-control_rate | info_mean, info_sd) - normal_cdf(-control_rate | info_mean, info_sd);
  real log_vague_normalizing_constant = log(vague_normalizing_constant);
  real log_info_normalizing_constant = log(info_normalizing_constant);
}
model {
  // Robust mixture prior

  control_rate ~ uniform(0, 1);

  target += log_mix(w,
		    normal_lpdf(treatment_effect | vague_mean, vague_sd) - log_vague_normalizing_constant,
		    normal_lpdf(treatment_effect | info_mean, info_sd) - log_info_normalizing_constant);

  successes_control ~ binomial(n_control, control_rate);
  successes_treatment ~ binomial(n_treatment, treatment_rate);
}
"


# Write the Stan code to a temporary file
stan_file_path <- cmdstanr::write_stan_file(stan_model_code)

# Compile the model
mod <- cmdstanr::cmdstan_model(stan_file_path)

# Specify the parameters
data_list <- list(
  w = 0.5,
  n_treatment = case_study_config$target$treatment,
  n_control = case_study_config$target$control,
  successes_treatment = case_study_config$target$responses$treatment,
  successes_control = case_study_config$target$responses$control,
  vague_mean = 0,
  vague_sd = sqrt(target_data$sample$treatment_effect_standard_error^2 * target_data$sample_size_per_arm),
  info_mean = case_study_config$source$treatment_effect,
  info_sd = case_study_config$source$standard_error
)

print(data_list)
```


We can now sample from the posterior: 
```{r, results='hide'}
# Sample from the posterior
fit <- mod$sample(
  data = data_list,
  chains = 4,
  parallel_chains = 4,
  iter_sampling = 2000,
  iter_warmup = 1000
)



bayesplot::mcmc_hist(fit$draws("treatment_effect"), binwidth = 0.001) + xlim(-1, 1)


hist(fit$draws("treatment_effect"), breaks = 10001, freq = FALSE)
```


By contrast, if we set w = 1 (equivalent to a separate analysis):

```{r, results='hide'}
# Specify the parameters
data_list$w <- 1

# Sample from the posterior
fit <- mod$sample(
  data = data_list,
  chains = 4,
  parallel_chains = 4,
  iter_sampling = 2000,
  iter_warmup = 1000
)
```

```{r}
bayesplot::mcmc_hist(fit$draws("treatment_effect"), binwidth = 0.001) + xlim(-1, 1)
hist(fit$draws("treatment_effect"), breaks = 10001, freq = FALSE)
```



## Sampling from the prior

Let us modify the Stan model to allow sampling from the prior distribution of the treatment effect: 

```{r}
stan_prior_code <- "
data {
  real<lower = 0, upper = 1> w;

  real vague_mean;
  real<lower = 0> vague_sd;
  real info_mean;
  real<lower = 0> info_sd;
}
transformed data {
  int<lower = 0, upper = 1> debug = 0;
}
parameters {
  real<lower = 0, upper = 1> control_rate;
  real<lower = -1, upper = 1> treatment_effect;
}
transformed parameters {
  real treatment_rate = control_rate + treatment_effect;
}
model {
  // Robust mixture prior

  control_rate ~ uniform(0, 1);

  real vague_normalizing_constant = normal_cdf(1-control_rate | vague_mean, vague_sd) - normal_cdf(-control_rate | vague_mean, vague_sd);
  real info_normalizing_constant = normal_cdf(1-control_rate | info_mean, info_sd) - normal_cdf(-control_rate | info_mean, info_sd);


  real log_vague_normalizing_constant = log(vague_normalizing_constant);
  real log_info_normalizing_constant = log(info_normalizing_constant);

  target += log_mix(w,
		    normal_lpdf(treatment_effect | vague_mean, vague_sd) - log_vague_normalizing_constant,
		    normal_lpdf(treatment_effect | info_mean, info_sd) - log_info_normalizing_constant);
}
"


# Write the Stan code to a temporary file
stan_file_path <- cmdstanr::write_stan_file(stan_prior_code)

# Compile the model
mod <- cmdstanr::cmdstan_model(stan_file_path)

# Specify the parameters
data_list <- list(
  w = 0.5,
  vague_mean = 0,
  vague_sd = sqrt(target_data$sample$treatment_effect_standard_error^2 * target_data$sample_size_per_arm),
  info_mean = case_study_config$source$treatment_effect,
  info_sd = case_study_config$source$standard_error
)
```


We can now sample from the posterior: 
```{r, results='hide'}
# Sample from the prior
fit <- mod$sample(
  data = data_list,
  chains = 4,
  parallel_chains = 4,
  iter_sampling = 2000,
  iter_warmup = 1000
)
```

```{r}
bayesplot::mcmc_hist(fit$draws("treatment_effect"), binwidth = 0.001) + xlim(-1, 1)


hist(fit$draws("treatment_effect"), breaks = 10001, freq = FALSE)
```


```{r}
library(posterior)
draws_array <- as_draws_array(fit)
```

```{r}
library(bayesplot)
mcmc_trace(draws_array, pars = c("tau", "power_parameter", "target_treatment_effect"))
```

```{r}
mcmc_acf(draws_array, pars = c("tau", "power_parameter", "target_treatment_effect"))
```


Actually, in the case of a mixture of truncated normal distributions, we can more easily sample directly from the prior using the truncnorm package. 

```{r}
# Load the truncnorm package
library(truncnorm)

n_samples <- 1000
w <- 0.5
vague_prior_mean <- 0
vague_prior_sd <- sqrt(target_data$sample$treatment_effect_standard_error^2 * target_data$sample_size_per_arm)
info_prior_mean <- case_study_config$source$treatment_effect
info_prior_sd <- case_study_config$source$standard_error

component_choice <- sample(
  x = c(0, 1),
  size = n_samples,
  replace = TRUE,
  prob = c(1 - w, w)
)

samples <- rep(0, n_samples)

lower <- -1 # Lower truncation point
upper <- 1 # Upper truncation point

samples[component_choice == 0] <- rtruncnorm(
  n = sum(component_choice == 0),
  mean = vague_prior_mean,
  sd = vague_prior_sd,
  a = lower,
  b = upper
)

samples[component_choice == 1] <- rtruncnorm(
  n = sum(component_choice == 1),
  mean = info_prior_mean,
  sd = info_prior_sd,
  a = lower,
  b = upper
)


# Plot the histogram of the samples
hist(samples, breaks = 30, main = "Histogram of Truncated Normal Distribution")
```
 
  
### Simulation 

Separate analysis:


```{r}
separate_method <- "separate"
method_parameters <- list(
  initial_prior = "noninformative", # This corresponds to the fact that the posterior for the adults data is derived from an uninformative prior (for consistency with other methods).
  empirical_bayes = FALSE # Corresponds to whether some parameters of the prior are based on observed data.
)

separate_model <- Model$new()

separate_model <- separate_model$create(
  case_study_config = case_study_config,
  method = separate_method,
  method_parameters = method_parameters,
  source_data = source_data
)
```

```{r}
treatment_effect_values <- seq(-7, 2, length.out = 50)

n <- length(treatment_effect_values)
confidence_level <- simulation_config$confidence_level
null_space <- case_study_config$null_space

n_replicates <- 100

separate_test_decisions <- matrix(rep(0, n * n_replicates), nrow = n)
separate_posterior_means <- matrix(rep(0, n * n_replicates), nrow = n)
separate_posterior_medians <- matrix(rep(0, n * n_replicates), nrow = n)
separate_credible_intervals <- array(rep(0, n * n_replicates * 2), dim = c(n, n_replicates, 2))
separate_prior_proba_no_benefit <- rep(0, n)

theta_0 <- case_study_config$theta_0

critical_value <- simulation_config$critical_value


for (i in seq_along(treatment_effect_values)) {
  drift <- treatment_effect_values[i] - source_data$treatment_effect_estimate
  target_data <- TargetDataFactory$new()

  target_data <- target_data$create(source_data = source_data, case_study_config = case_study_config, target_sample_size_per_arm = target_sample_size_per_arm, treatment_drift = drift, summary_measure_likelihood = source_data$summary_measure_likelihood)

  results <- separate_model$simulation_for_given_treatment_effect(target_data = target_data, n_replicates = n_replicates, critical_value = critical_value, theta_0 = theta_0, confidence_level = confidence_level, null_space = null_space, to_return = c("test_decision"), method = method, case_study = case_study)

  separate_test_decisions[i, ] <- results$test_decisions
  separate_posterior_means[i, ] <- results$posterior_means
  separate_posterior_medians[i, ] <- results$posterior_medians
  separate_credible_intervals[i, , ] <- matrix(results$credible_intervals, nrow = n_replicates)
}
```


```{r} 
test_decisions <- matrix(rep(0, n * n_replicates), nrow = n)
posterior_means <- matrix(rep(0, n * n_replicates), nrow = n)
posterior_medians <- matrix(rep(0, n * n_replicates), nrow = n)
credible_intervals <- array(rep(0, n * n_replicates * 2), dim = c(n, n_replicates, 2))
prior_proba_no_benefit <- rep(0, n)

for (i in seq_along(treatment_effect_values)) {
  drift <- treatment_effect_values[i] - source_data$treatment_effect_estimate # This implies that target_data$treatment_effect <- treatment_effect_values[i]
  target_data <- TargetDataFactory$new()

  target_data <- target_data$create(source_data = source_data, case_study_config = case_study_config, target_sample_size_per_arm = target_sample_size_per_arm, treatment_drift = drift, summary_measure_likelihood = source_data$summary_measure_likelihood)

  # target_data$sampling_approximation <- TRUE
  results <- model$simulation_for_given_treatment_effect(target_data = target_data, n_replicates = n_replicates, critical_value = critical_value, theta_0 = theta_0, confidence_level = confidence_level, null_space = null_space, to_return = c("test_decision"),  method = method, case_study = case_study)

  test_decisions[i, ] <- results$test_decisions
  posterior_means[i, ] <- results$posterior_means
  posterior_medians[i, ] <- results$posterior_medians
  credible_intervals[i, , ] <- matrix(results$credible_intervals, nrow = n_replicates)
}
```
 
```{r}
conditional_proba_success <- rowMeans(test_decisions) # Contains Pr(Study success | theta_T)
data <- data.frame(conditional_proba_success = conditional_proba_success, treatment_effect_values = treatment_effect_values, method = method)

separate_conditional_proba_success <- rowMeans(separate_test_decisions) # Contains Pr(Study success | theta_T)

separate_data <- data.frame(conditional_proba_success = separate_conditional_proba_success, treatment_effect_values = treatment_effect_values, method = separate_method)

combined_data <- rbind(data, separate_data)

plt <- ggplot(combined_data, aes(x = treatment_effect_values, y = conditional_proba_success, color = method)) +
  geom_point() +
  ggplot2::labs(
    title = "Posterior mean vs Target Treatment Effect",
    x = "Target Treatment Effect",
    y = "Success probability",
    color = "Method"
  ) +
  theme_minimal()

print(plt)
```
```{r}
separate_conditional_posterior_means <- rowMeans(separate_posterior_means)
separate_data <- data.frame(conditional_posterior_means = separate_conditional_posterior_means, treatment_effect_values = treatment_effect_values, method = separate_method)

conditional_posterior_means <- rowMeans(posterior_means)
data <- data.frame(conditional_posterior_means = conditional_posterior_means, treatment_effect_values = treatment_effect_values, method = method)

combined_data <- rbind(data, separate_data)

plt <- ggplot(combined_data, aes(x = treatment_effect_values, y = conditional_posterior_means, color = method)) +
  geom_point() +
  ggplot2::labs(
    title = "Posterior mean vs Target Treatment Effect",
    x = "Target Treatment Effect",
    y = "Posterior mean",
    color = "Method"
  ) +
  theme_minimal()

print(plt)
```

```{r}
sessionInfo()
```
 
